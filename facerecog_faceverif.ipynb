{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cBTItUallco"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import gc\n",
        "import shutil\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "import torchvision.transforms as ttf\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL1D13eHuD_g",
        "outputId": "10eb28bc-fe68-4280-db53-1f075a045a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 34.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 9.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEtazqufyer1"
      },
      "outputs": [],
      "source": [
        "from timm.models.layers import trunc_normal_, DropPath\n",
        "from timm.models.registry import register_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDipd9cBiVgD",
        "outputId": "f1577f6b-10f4-4228-cc8f-18c110b835b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.10.0+cu111\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIii-hn3l3bZ"
      },
      "source": [
        "## Downloading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pza6rtaCmXRa"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXR-ZN27l9Cz",
        "outputId": "b5447ec7-2f8a-461e-9709-5c962fb06113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaggle==1.5.8\n",
            "  Downloading kaggle-1.5.8.tar.gz (59 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▌                          | 10 kB 32.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20 kB 40.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 30 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 40 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 51 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 59 kB 4.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.8-py3-none-any.whl size=73275 sha256=a493a606ddb3de1678b8084d229d0bdfe9925852911874e0315b286dc46dd097\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/f7/d8/c3902cacb7e62cb611b1ad343d7cc07f42f7eb76ae3a52f3d1\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.8\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "# writing kaggle username & key to the json file\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"shrikiransrinivasan\",\"key\":\"8d8c6f44ec36fd64dd50f328913ac2a7\"}')\n",
        "\n",
        "# chmod command controls who can do what to a file or directory in linux\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9GeaHo5xpvV",
        "outputId": "41147741-bfae-4eea-c722-39cae904d7a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMTNRlaUz-Hc",
        "outputId": "ef1c0d89-6970-4083-c3ec-2e033fd88230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "# drive._mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5IiokK-mG_J",
        "outputId": "bba2426b-439b-4cd4-a094-85dc13e4ab25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 11-785-s22-hw2p2-classification.zip to /content\n",
            "100% 2.35G/2.35G [00:29<00:00, 85.0MB/s]\n",
            "100% 2.35G/2.35G [00:29<00:00, 86.6MB/s]\n",
            "Downloading 11-785-s22-hw2p2-verification.zip to /content\n",
            "100% 263M/263M [00:03<00:00, 94.9MB/s]\n",
            "100% 263M/263M [00:03<00:00, 84.7MB/s]\n",
            "11-785-s22-hw2p2-classification.zip   sample_data\n",
            "11-785-s22-hw2p2-verification.zip     train_subset\n",
            "classification\t\t\t      verification\n",
            "classification_sample_submission.csv  verification_sample_submission.csv\n",
            "drive\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c 11-785-s22-hw2p2-classification\n",
        "!kaggle competitions download -c 11-785-s22-hw2p2-verification\n",
        "\n",
        "!unzip -q 11-785-s22-hw2p2-classification.zip\n",
        "!unzip -q 11-785-s22-hw2p2-verification.zip\n",
        "\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH0tavf2orhA"
      },
      "source": [
        "## Setting Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC7PodvuouQD"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "The well-accepted SGD batch_size & lr combination for CNN classification is 256 batch size for 0.1 learning rate.\n",
        "When changing batch size for SGD, follow the linear scaling rule - halving batch size -> halve learning rate, etc.\n",
        "This is less theoretically supported for Adam, but in my experience, it's a decent ballpark estimate.\n",
        "\"\"\"\n",
        "batch_size = 200\n",
        "lr = 0.1\n",
        "n_epochs = 70 # Just for the early submission. We'd want you to train like 50 epochs for your main submissions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btptNF3owqEQ",
        "outputId": "3ca0ce3e-4849-410b-a600-123229e0d81a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Mar 10 02:57:37 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    37W / 250W |  16151MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpEM2ZEVo8F-"
      },
      "source": [
        "## The Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLSROKDwArZZ"
      },
      "source": [
        "Normal Convnet class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zr3RYwEwpAAx"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "  \n",
        "    def __init__(self, num_classes=7000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.backbone = nn.Sequential(\n",
        "\n",
        "            # TODO: Conv group 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(7,7), stride=(4,4)),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            # TODO: Conv group 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            # TODO: Conv group 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            # TODO: Conv group 4\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=(3,3), stride=(2,2)),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # TODO: Average pool over & reduce the spatial dimensions to (1, 1)\n",
        "            # nn.AvgPool2d((6,6)), --> this works too, but have to do calculations to find (6,6)\n",
        "            nn.AdaptiveAvgPool2d([1,1]),\n",
        "\n",
        "            # TODO: Collapse (Flatten) the trivial (1, 1) dimensions\n",
        "            nn.Flatten()\n",
        "            ) \n",
        "        \n",
        "        self.cls_layer = nn.Linear(512, num_classes)\n",
        "    \n",
        "    def forward(self, x, return_feats=False):\n",
        "        \"\"\"\n",
        "        What is return_feats? It essentially returns the second-to-last-layer\n",
        "        features of a given image. It's a \"feature encoding\" of the input image,\n",
        "        and you can use it for the verification task. You would use the outputs\n",
        "        of the final classification layer for the classification task.\n",
        "\n",
        "        You might also find that the classification outputs are sometimes better\n",
        "        for verification too - try both.\n",
        "        \"\"\"\n",
        "        feats = self.backbone(x)\n",
        "        out = self.cls_layer(feats)\n",
        "\n",
        "        if return_feats:\n",
        "            return feats\n",
        "        else:\n",
        "            return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bONf-ltS5YnC"
      },
      "source": [
        "Residual block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGijrpEt5Wt1"
      },
      "outputs": [],
      "source": [
        "class InvertedResidualBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 stride,\n",
        "                 expand_ratio):\n",
        "        super().__init__() # Just have to do this for all nn.Module classes\n",
        "\n",
        "        # Can only do identity residual connection if input & output are the\n",
        "        # same channel & spatial shape.\n",
        "        if stride == 1 and in_channels == out_channels:\n",
        "            self.do_identity = True\n",
        "        else:\n",
        "            self.do_identity = False\n",
        "        \n",
        "        # Expand Ratio is like 6, so hidden_dim >> in_channels\n",
        "        hidden_dim = in_channels * expand_ratio\n",
        "\n",
        "        self.feature_mixing = nn.Sequential(\n",
        "            # TODO: Fill this in!\n",
        "            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(hidden_dim),\n",
        "            nn.ReLU6(),\n",
        "        )\n",
        "\n",
        "        self.spatial_mixing = nn.Sequential(\n",
        "            # TODO: Fill this in!\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, padding=1,\n",
        "                      stride=stride, groups=hidden_dim, bias=False),\n",
        "            nn.BatchNorm2d(hidden_dim),\n",
        "            nn.ReLU6(),\n",
        "        )\n",
        "\n",
        "        self.bottleneck_channels = nn.Sequential(\n",
        "            # TODO: Fill this in!\n",
        "            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.feature_mixing(x) # pointwise convolutions, sudden increase in number of channels\n",
        "        out = self.spatial_mixing(out) # depthwise convolutions, no of channels remains the same\n",
        "        out = self.bottleneck_channels(out)\n",
        "\n",
        "        if self.do_identity:\n",
        "            return x + out # add input to output if no of channels remains the same\n",
        "        else:\n",
        "            return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xndRQok56NY9"
      },
      "source": [
        "MobileNet class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAR_vP2-6Md4"
      },
      "outputs": [],
      "source": [
        "class MobileNetV2(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes= 7000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.stem = nn.Sequential(\n",
        "            # TODO: Fill this in!\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU6(),\n",
        "            nn.Conv2d(32, 32, kernel_size=1, padding=1, groups=32, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU6(),\n",
        "            nn.Conv2d(32, 16, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            \n",
        "              \n",
        "        )\n",
        "\n",
        "        \"\"\"\n",
        "        The four numbers in each row (a stage) are shown below.\n",
        "        - Expand ratio: We talked about this in InvertedResidualBlock\n",
        "        - Channels: This specifies the channel size before expansion\n",
        "        - # blocks: Each stage has many blocks, how many?\n",
        "        - Stride of first block: For some stages, we want to downsample. In a\n",
        "          downsampling stage, we set the first block in that stage to have\n",
        "          stride = 2, and the rest just have stride = 1.\n",
        "\n",
        "        Again, note that almost every stage here is downsampling! By the time\n",
        "        we get to the last stage, what is the image resolution? Can it still\n",
        "        be called an image for our dataset? Think about this, and make changes\n",
        "        as you want.\n",
        "        \"\"\"\n",
        "        self.stage_cfgs = [\n",
        "            # expand_ratio, channels, # blocks, stride of first block\n",
        "            [6,  24, 2, 2],\n",
        "            [6,  32, 3, 2],\n",
        "            [6,  64, 4, 2],\n",
        "            [6,  96, 3, 1],\n",
        "            [6, 160, 3, 2],\n",
        "            [6, 320, 1, 1],\n",
        "        ]\n",
        "\n",
        "        # Remember that our stem left us off at 16 channels. We're going to \n",
        "        # keep updating this in_channels variable as we go\n",
        "        in_channels = 16\n",
        "\n",
        "        # Let's make the layers\n",
        "        layers = []\n",
        "        for curr_stage in self.stage_cfgs:\n",
        "            expand_ratio, num_channels, num_blocks, stride = curr_stage\n",
        "            \n",
        "            for block_idx in range(num_blocks):\n",
        "                out_channels = num_channels\n",
        "                layers.append(InvertedResidualBlock(\n",
        "                    in_channels=in_channels,\n",
        "                    out_channels=out_channels,\n",
        "                    # only have non-trivial stride if first block\n",
        "                    stride=stride if block_idx == 0 else 1, \n",
        "                    expand_ratio=expand_ratio\n",
        "                ))\n",
        "                # print(\"in: \" + str(in_channels))\n",
        "                # print(\"out: \" + str(out_channels))\n",
        "                # print(\"\\n\")\n",
        "                # In channels of the next block is the out_channels of the current one\n",
        "                in_channels = out_channels \n",
        "            \n",
        "        self.layers = nn.Sequential(*layers) # Done, save them to the class\n",
        "\n",
        "        # Some final feature mixing\n",
        "        self.final_block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 1280, kernel_size=1, padding=0, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(1280),\n",
        "            nn.ReLU6()\n",
        "        )\n",
        "\n",
        "        # Now, we need to build the final classification layer.\n",
        "        self.cls_layer = nn.Sequential(\n",
        "            # TODO: Fill this in!\n",
        "            # Pool over & collapse the spatial dimensions to (1, 1)\n",
        "            # Collapse the trivial (1, 1) dimensions\n",
        "            # Project to our # of classes\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        # Separating linear layer so features can be extracted for verification\n",
        "        self.lin = nn.Linear(1280, num_classes)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"\n",
        "        Usually, I like to use default pytorch initialization for stuff, but\n",
        "        MobileNetV2 made a point of putting in some custom ones, so let's just\n",
        "        use them.\n",
        "        \"\"\"\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, return_feats=False):\n",
        "        out = self.stem(x)\n",
        "        out = self.layers(out)\n",
        "        out = self.final_block(out)\n",
        "        feats = self.cls_layer(out)\n",
        "        out = self.lin(feats)\n",
        "\n",
        "        if return_feats:\n",
        "            return feats\n",
        "        else:\n",
        "            return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR6OOnZcXUhQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "946265d4-7b04-40e7-bcc7-96f8ff715e61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "in: 16\n",
            "out: 24\n",
            "\n",
            "\n",
            "in: 24\n",
            "out: 24\n",
            "\n",
            "\n",
            "in: 24\n",
            "out: 32\n",
            "\n",
            "\n",
            "in: 32\n",
            "out: 32\n",
            "\n",
            "\n",
            "in: 32\n",
            "out: 32\n",
            "\n",
            "\n",
            "in: 32\n",
            "out: 64\n",
            "\n",
            "\n",
            "in: 64\n",
            "out: 64\n",
            "\n",
            "\n",
            "in: 64\n",
            "out: 64\n",
            "\n",
            "\n",
            "in: 64\n",
            "out: 64\n",
            "\n",
            "\n",
            "in: 64\n",
            "out: 96\n",
            "\n",
            "\n",
            "in: 96\n",
            "out: 96\n",
            "\n",
            "\n",
            "in: 96\n",
            "out: 96\n",
            "\n",
            "\n",
            "in: 96\n",
            "out: 160\n",
            "\n",
            "\n",
            "in: 160\n",
            "out: 160\n",
            "\n",
            "\n",
            "in: 160\n",
            "out: 160\n",
            "\n",
            "\n",
            "in: 160\n",
            "out: 320\n",
            "\n",
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 112, 112]             864\n",
            "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
            "             ReLU6-3         [-1, 32, 112, 112]               0\n",
            "            Conv2d-4         [-1, 32, 114, 114]              32\n",
            "       BatchNorm2d-5         [-1, 32, 114, 114]              64\n",
            "             ReLU6-6         [-1, 32, 114, 114]               0\n",
            "            Conv2d-7         [-1, 16, 114, 114]             512\n",
            "       BatchNorm2d-8         [-1, 16, 114, 114]              32\n",
            "            Conv2d-9         [-1, 96, 114, 114]           1,536\n",
            "      BatchNorm2d-10         [-1, 96, 114, 114]             192\n",
            "            ReLU6-11         [-1, 96, 114, 114]               0\n",
            "           Conv2d-12           [-1, 96, 57, 57]             864\n",
            "      BatchNorm2d-13           [-1, 96, 57, 57]             192\n",
            "            ReLU6-14           [-1, 96, 57, 57]               0\n",
            "           Conv2d-15           [-1, 24, 57, 57]           2,304\n",
            "      BatchNorm2d-16           [-1, 24, 57, 57]              48\n",
            "InvertedResidualBlock-17           [-1, 24, 57, 57]               0\n",
            "           Conv2d-18          [-1, 144, 57, 57]           3,456\n",
            "      BatchNorm2d-19          [-1, 144, 57, 57]             288\n",
            "            ReLU6-20          [-1, 144, 57, 57]               0\n",
            "           Conv2d-21          [-1, 144, 57, 57]           1,296\n",
            "      BatchNorm2d-22          [-1, 144, 57, 57]             288\n",
            "            ReLU6-23          [-1, 144, 57, 57]               0\n",
            "           Conv2d-24           [-1, 24, 57, 57]           3,456\n",
            "      BatchNorm2d-25           [-1, 24, 57, 57]              48\n",
            "InvertedResidualBlock-26           [-1, 24, 57, 57]               0\n",
            "           Conv2d-27          [-1, 144, 57, 57]           3,456\n",
            "      BatchNorm2d-28          [-1, 144, 57, 57]             288\n",
            "            ReLU6-29          [-1, 144, 57, 57]               0\n",
            "           Conv2d-30          [-1, 144, 29, 29]           1,296\n",
            "      BatchNorm2d-31          [-1, 144, 29, 29]             288\n",
            "            ReLU6-32          [-1, 144, 29, 29]               0\n",
            "           Conv2d-33           [-1, 32, 29, 29]           4,608\n",
            "      BatchNorm2d-34           [-1, 32, 29, 29]              64\n",
            "InvertedResidualBlock-35           [-1, 32, 29, 29]               0\n",
            "           Conv2d-36          [-1, 192, 29, 29]           6,144\n",
            "      BatchNorm2d-37          [-1, 192, 29, 29]             384\n",
            "            ReLU6-38          [-1, 192, 29, 29]               0\n",
            "           Conv2d-39          [-1, 192, 29, 29]           1,728\n",
            "      BatchNorm2d-40          [-1, 192, 29, 29]             384\n",
            "            ReLU6-41          [-1, 192, 29, 29]               0\n",
            "           Conv2d-42           [-1, 32, 29, 29]           6,144\n",
            "      BatchNorm2d-43           [-1, 32, 29, 29]              64\n",
            "InvertedResidualBlock-44           [-1, 32, 29, 29]               0\n",
            "           Conv2d-45          [-1, 192, 29, 29]           6,144\n",
            "      BatchNorm2d-46          [-1, 192, 29, 29]             384\n",
            "            ReLU6-47          [-1, 192, 29, 29]               0\n",
            "           Conv2d-48          [-1, 192, 29, 29]           1,728\n",
            "      BatchNorm2d-49          [-1, 192, 29, 29]             384\n",
            "            ReLU6-50          [-1, 192, 29, 29]               0\n",
            "           Conv2d-51           [-1, 32, 29, 29]           6,144\n",
            "      BatchNorm2d-52           [-1, 32, 29, 29]              64\n",
            "InvertedResidualBlock-53           [-1, 32, 29, 29]               0\n",
            "           Conv2d-54          [-1, 192, 29, 29]           6,144\n",
            "      BatchNorm2d-55          [-1, 192, 29, 29]             384\n",
            "            ReLU6-56          [-1, 192, 29, 29]               0\n",
            "           Conv2d-57          [-1, 192, 15, 15]           1,728\n",
            "      BatchNorm2d-58          [-1, 192, 15, 15]             384\n",
            "            ReLU6-59          [-1, 192, 15, 15]               0\n",
            "           Conv2d-60           [-1, 64, 15, 15]          12,288\n",
            "      BatchNorm2d-61           [-1, 64, 15, 15]             128\n",
            "InvertedResidualBlock-62           [-1, 64, 15, 15]               0\n",
            "           Conv2d-63          [-1, 384, 15, 15]          24,576\n",
            "      BatchNorm2d-64          [-1, 384, 15, 15]             768\n",
            "            ReLU6-65          [-1, 384, 15, 15]               0\n",
            "           Conv2d-66          [-1, 384, 15, 15]           3,456\n",
            "      BatchNorm2d-67          [-1, 384, 15, 15]             768\n",
            "            ReLU6-68          [-1, 384, 15, 15]               0\n",
            "           Conv2d-69           [-1, 64, 15, 15]          24,576\n",
            "      BatchNorm2d-70           [-1, 64, 15, 15]             128\n",
            "InvertedResidualBlock-71           [-1, 64, 15, 15]               0\n",
            "           Conv2d-72          [-1, 384, 15, 15]          24,576\n",
            "      BatchNorm2d-73          [-1, 384, 15, 15]             768\n",
            "            ReLU6-74          [-1, 384, 15, 15]               0\n",
            "           Conv2d-75          [-1, 384, 15, 15]           3,456\n",
            "      BatchNorm2d-76          [-1, 384, 15, 15]             768\n",
            "            ReLU6-77          [-1, 384, 15, 15]               0\n",
            "           Conv2d-78           [-1, 64, 15, 15]          24,576\n",
            "      BatchNorm2d-79           [-1, 64, 15, 15]             128\n",
            "InvertedResidualBlock-80           [-1, 64, 15, 15]               0\n",
            "           Conv2d-81          [-1, 384, 15, 15]          24,576\n",
            "      BatchNorm2d-82          [-1, 384, 15, 15]             768\n",
            "            ReLU6-83          [-1, 384, 15, 15]               0\n",
            "           Conv2d-84          [-1, 384, 15, 15]           3,456\n",
            "      BatchNorm2d-85          [-1, 384, 15, 15]             768\n",
            "            ReLU6-86          [-1, 384, 15, 15]               0\n",
            "           Conv2d-87           [-1, 64, 15, 15]          24,576\n",
            "      BatchNorm2d-88           [-1, 64, 15, 15]             128\n",
            "InvertedResidualBlock-89           [-1, 64, 15, 15]               0\n",
            "           Conv2d-90          [-1, 384, 15, 15]          24,576\n",
            "      BatchNorm2d-91          [-1, 384, 15, 15]             768\n",
            "            ReLU6-92          [-1, 384, 15, 15]               0\n",
            "           Conv2d-93          [-1, 384, 15, 15]           3,456\n",
            "      BatchNorm2d-94          [-1, 384, 15, 15]             768\n",
            "            ReLU6-95          [-1, 384, 15, 15]               0\n",
            "           Conv2d-96           [-1, 96, 15, 15]          36,864\n",
            "      BatchNorm2d-97           [-1, 96, 15, 15]             192\n",
            "InvertedResidualBlock-98           [-1, 96, 15, 15]               0\n",
            "           Conv2d-99          [-1, 576, 15, 15]          55,296\n",
            "     BatchNorm2d-100          [-1, 576, 15, 15]           1,152\n",
            "           ReLU6-101          [-1, 576, 15, 15]               0\n",
            "          Conv2d-102          [-1, 576, 15, 15]           5,184\n",
            "     BatchNorm2d-103          [-1, 576, 15, 15]           1,152\n",
            "           ReLU6-104          [-1, 576, 15, 15]               0\n",
            "          Conv2d-105           [-1, 96, 15, 15]          55,296\n",
            "     BatchNorm2d-106           [-1, 96, 15, 15]             192\n",
            "InvertedResidualBlock-107           [-1, 96, 15, 15]               0\n",
            "          Conv2d-108          [-1, 576, 15, 15]          55,296\n",
            "     BatchNorm2d-109          [-1, 576, 15, 15]           1,152\n",
            "           ReLU6-110          [-1, 576, 15, 15]               0\n",
            "          Conv2d-111          [-1, 576, 15, 15]           5,184\n",
            "     BatchNorm2d-112          [-1, 576, 15, 15]           1,152\n",
            "           ReLU6-113          [-1, 576, 15, 15]               0\n",
            "          Conv2d-114           [-1, 96, 15, 15]          55,296\n",
            "     BatchNorm2d-115           [-1, 96, 15, 15]             192\n",
            "InvertedResidualBlock-116           [-1, 96, 15, 15]               0\n",
            "          Conv2d-117          [-1, 576, 15, 15]          55,296\n",
            "     BatchNorm2d-118          [-1, 576, 15, 15]           1,152\n",
            "           ReLU6-119          [-1, 576, 15, 15]               0\n",
            "          Conv2d-120            [-1, 576, 8, 8]           5,184\n",
            "     BatchNorm2d-121            [-1, 576, 8, 8]           1,152\n",
            "           ReLU6-122            [-1, 576, 8, 8]               0\n",
            "          Conv2d-123            [-1, 160, 8, 8]          92,160\n",
            "     BatchNorm2d-124            [-1, 160, 8, 8]             320\n",
            "InvertedResidualBlock-125            [-1, 160, 8, 8]               0\n",
            "          Conv2d-126            [-1, 960, 8, 8]         153,600\n",
            "     BatchNorm2d-127            [-1, 960, 8, 8]           1,920\n",
            "           ReLU6-128            [-1, 960, 8, 8]               0\n",
            "          Conv2d-129            [-1, 960, 8, 8]           8,640\n",
            "     BatchNorm2d-130            [-1, 960, 8, 8]           1,920\n",
            "           ReLU6-131            [-1, 960, 8, 8]               0\n",
            "          Conv2d-132            [-1, 160, 8, 8]         153,600\n",
            "     BatchNorm2d-133            [-1, 160, 8, 8]             320\n",
            "InvertedResidualBlock-134            [-1, 160, 8, 8]               0\n",
            "          Conv2d-135            [-1, 960, 8, 8]         153,600\n",
            "     BatchNorm2d-136            [-1, 960, 8, 8]           1,920\n",
            "           ReLU6-137            [-1, 960, 8, 8]               0\n",
            "          Conv2d-138            [-1, 960, 8, 8]           8,640\n",
            "     BatchNorm2d-139            [-1, 960, 8, 8]           1,920\n",
            "           ReLU6-140            [-1, 960, 8, 8]               0\n",
            "          Conv2d-141            [-1, 160, 8, 8]         153,600\n",
            "     BatchNorm2d-142            [-1, 160, 8, 8]             320\n",
            "InvertedResidualBlock-143            [-1, 160, 8, 8]               0\n",
            "          Conv2d-144            [-1, 960, 8, 8]         153,600\n",
            "     BatchNorm2d-145            [-1, 960, 8, 8]           1,920\n",
            "           ReLU6-146            [-1, 960, 8, 8]               0\n",
            "          Conv2d-147            [-1, 960, 8, 8]           8,640\n",
            "     BatchNorm2d-148            [-1, 960, 8, 8]           1,920\n",
            "           ReLU6-149            [-1, 960, 8, 8]               0\n",
            "          Conv2d-150            [-1, 320, 8, 8]         307,200\n",
            "     BatchNorm2d-151            [-1, 320, 8, 8]             640\n",
            "InvertedResidualBlock-152            [-1, 320, 8, 8]               0\n",
            "          Conv2d-153           [-1, 1280, 8, 8]         409,600\n",
            "     BatchNorm2d-154           [-1, 1280, 8, 8]           2,560\n",
            "           ReLU6-155           [-1, 1280, 8, 8]               0\n",
            "AdaptiveAvgPool2d-156           [-1, 1280, 1, 1]               0\n",
            "         Flatten-157                 [-1, 1280]               0\n",
            "          Linear-158                 [-1, 7000]       8,967,000\n",
            "================================================================\n",
            "Total params: 11,190,616\n",
            "Trainable params: 11,190,616\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 163.21\n",
            "Params size (MB): 42.69\n",
            "Estimated Total Size (MB): 206.47\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = MobileNetV2() #initializing an instance of Network class\n",
        "model.cuda() \n",
        "summary(model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bit6Ab3yIjNT"
      },
      "source": [
        "ConvNext block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXEnOzH8r_hH"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self, in_channels, drop_path):\n",
        "    super().__init__()\n",
        "    self.dwconv = nn.Conv2d(in_channels,in_channels,kernel_size=7, padding=3, groups=in_channels)\n",
        "    self.bn = nn.BatchNorm2d(in_channels)\n",
        "    self.pwconv1 = nn.Conv2d(in_channels, 4*in_channels, kernel_size=1, stride=1)\n",
        "    self.act = nn.GELU()\n",
        "    self.pwconv2 = nn.Conv2d(4*in_channels, in_channels, kernel_size=1, stride=1)\n",
        "    self.drop_path = DropPath(drop_path) if drop_path > 0 else nn.Identity()\n",
        "\n",
        "  def forward(self, x):\n",
        "    input = x\n",
        "    out = self.dwconv(x)\n",
        "    out = self.bn(out)\n",
        "    out = self.pwconv1(out)\n",
        "    out = self.act(out)\n",
        "    out = self.pwconv2(out)\n",
        "    out = input + self.drop_path(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zN5bowxcuo_2"
      },
      "outputs": [],
      "source": [
        "class ConvNext(nn.Module):\n",
        "  def __init__(self, in_channels, num_classes=7000, depths=[3,3,9,3], \n",
        "               dims=[96, 192, 384, 758], drop_path_rate=0.0):\n",
        "    super().__init__()\n",
        "    self.down_sample_layers = nn.ModuleList()\n",
        "    stem = nn.Sequential(nn.Conv2d(in_channels, dims[0], kernel_size=4, stride=4),\n",
        "                         nn.BatchNorm2d(dims[0]))\n",
        "    self.down_sample_layers.append(stem)\n",
        "\n",
        "    for i in range(3):\n",
        "      down_sample_layer = nn.Sequential(\n",
        "          nn.BatchNorm2d(dims[i]),\n",
        "          nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2)\n",
        "      )\n",
        "      self.down_sample_layers.append(down_sample_layer)\n",
        "\n",
        "      dp_rates = [x.item() for x in np.linspace(drop_path_rate, 0.0, sum(depths) )]\n",
        "      self.block_layers = nn.ModuleList()\n",
        "\n",
        "      for i in range(4):\n",
        "        blocks = nn.ModuleList()\n",
        "        for j in range(depths[i]):\n",
        "          block = Block(dims[i], dp_rates[sum(depths[:i]) + j])\n",
        "          blocks.append(block)\n",
        "        self.block_layers.append(nn.Sequential(*blocks))\n",
        "\n",
        "    self.norm = nn.BatchNorm2d(dims[-1])\n",
        "    self.classifier = nn.Linear(dims[-1], num_classes)\n",
        "\n",
        "  def forward(self, x, return_features=False):\n",
        "    for i in range(4):\n",
        "      x = self.down_sample_layers[i](x)\n",
        "      x = self.block_layers[i](x)\n",
        "\n",
        "    x = self.norm(x)\n",
        "    x = F.adaptive_avg_pool2d(x,1)\n",
        "    feats = x.view(x.size(0), -1)\n",
        "    x = self.classifier(feats)\n",
        "    \n",
        "    out = torch.nn.functional.gelu(torch.nn.functional.gelu(torch.nn.functional.gelu(torch.nn.functional.gelu(x))))\n",
        "\n",
        "    if return_features:\n",
        "      return out\n",
        "    else:\n",
        "      return x\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2wgYViZ1Rly",
        "outputId": "20bd3ac7-9a16-4f7c-9972-8384800ed872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 56, 56]           4,704\n",
            "       BatchNorm2d-2           [-1, 96, 56, 56]             192\n",
            "            Conv2d-3           [-1, 96, 56, 56]           4,800\n",
            "       BatchNorm2d-4           [-1, 96, 56, 56]             192\n",
            "            Conv2d-5          [-1, 384, 56, 56]          37,248\n",
            "              GELU-6          [-1, 384, 56, 56]               0\n",
            "            Conv2d-7           [-1, 96, 56, 56]          36,960\n",
            "          Identity-8           [-1, 96, 56, 56]               0\n",
            "             Block-9           [-1, 96, 56, 56]               0\n",
            "           Conv2d-10           [-1, 96, 56, 56]           4,800\n",
            "      BatchNorm2d-11           [-1, 96, 56, 56]             192\n",
            "           Conv2d-12          [-1, 384, 56, 56]          37,248\n",
            "             GELU-13          [-1, 384, 56, 56]               0\n",
            "           Conv2d-14           [-1, 96, 56, 56]          36,960\n",
            "         Identity-15           [-1, 96, 56, 56]               0\n",
            "            Block-16           [-1, 96, 56, 56]               0\n",
            "           Conv2d-17           [-1, 96, 56, 56]           4,800\n",
            "      BatchNorm2d-18           [-1, 96, 56, 56]             192\n",
            "           Conv2d-19          [-1, 384, 56, 56]          37,248\n",
            "             GELU-20          [-1, 384, 56, 56]               0\n",
            "           Conv2d-21           [-1, 96, 56, 56]          36,960\n",
            "         Identity-22           [-1, 96, 56, 56]               0\n",
            "            Block-23           [-1, 96, 56, 56]               0\n",
            "      BatchNorm2d-24           [-1, 96, 56, 56]             192\n",
            "           Conv2d-25          [-1, 192, 28, 28]          73,920\n",
            "           Conv2d-26          [-1, 192, 28, 28]           9,600\n",
            "      BatchNorm2d-27          [-1, 192, 28, 28]             384\n",
            "           Conv2d-28          [-1, 768, 28, 28]         148,224\n",
            "             GELU-29          [-1, 768, 28, 28]               0\n",
            "           Conv2d-30          [-1, 192, 28, 28]         147,648\n",
            "         Identity-31          [-1, 192, 28, 28]               0\n",
            "            Block-32          [-1, 192, 28, 28]               0\n",
            "           Conv2d-33          [-1, 192, 28, 28]           9,600\n",
            "      BatchNorm2d-34          [-1, 192, 28, 28]             384\n",
            "           Conv2d-35          [-1, 768, 28, 28]         148,224\n",
            "             GELU-36          [-1, 768, 28, 28]               0\n",
            "           Conv2d-37          [-1, 192, 28, 28]         147,648\n",
            "         Identity-38          [-1, 192, 28, 28]               0\n",
            "            Block-39          [-1, 192, 28, 28]               0\n",
            "           Conv2d-40          [-1, 192, 28, 28]           9,600\n",
            "      BatchNorm2d-41          [-1, 192, 28, 28]             384\n",
            "           Conv2d-42          [-1, 768, 28, 28]         148,224\n",
            "             GELU-43          [-1, 768, 28, 28]               0\n",
            "           Conv2d-44          [-1, 192, 28, 28]         147,648\n",
            "         Identity-45          [-1, 192, 28, 28]               0\n",
            "            Block-46          [-1, 192, 28, 28]               0\n",
            "      BatchNorm2d-47          [-1, 192, 28, 28]             384\n",
            "           Conv2d-48          [-1, 384, 14, 14]         295,296\n",
            "           Conv2d-49          [-1, 384, 14, 14]          19,200\n",
            "      BatchNorm2d-50          [-1, 384, 14, 14]             768\n",
            "           Conv2d-51         [-1, 1536, 14, 14]         591,360\n",
            "             GELU-52         [-1, 1536, 14, 14]               0\n",
            "           Conv2d-53          [-1, 384, 14, 14]         590,208\n",
            "         Identity-54          [-1, 384, 14, 14]               0\n",
            "            Block-55          [-1, 384, 14, 14]               0\n",
            "           Conv2d-56          [-1, 384, 14, 14]          19,200\n",
            "      BatchNorm2d-57          [-1, 384, 14, 14]             768\n",
            "           Conv2d-58         [-1, 1536, 14, 14]         591,360\n",
            "             GELU-59         [-1, 1536, 14, 14]               0\n",
            "           Conv2d-60          [-1, 384, 14, 14]         590,208\n",
            "         Identity-61          [-1, 384, 14, 14]               0\n",
            "            Block-62          [-1, 384, 14, 14]               0\n",
            "           Conv2d-63          [-1, 384, 14, 14]          19,200\n",
            "      BatchNorm2d-64          [-1, 384, 14, 14]             768\n",
            "           Conv2d-65         [-1, 1536, 14, 14]         591,360\n",
            "             GELU-66         [-1, 1536, 14, 14]               0\n",
            "           Conv2d-67          [-1, 384, 14, 14]         590,208\n",
            "         Identity-68          [-1, 384, 14, 14]               0\n",
            "            Block-69          [-1, 384, 14, 14]               0\n",
            "           Conv2d-70          [-1, 384, 14, 14]          19,200\n",
            "      BatchNorm2d-71          [-1, 384, 14, 14]             768\n",
            "           Conv2d-72         [-1, 1536, 14, 14]         591,360\n",
            "             GELU-73         [-1, 1536, 14, 14]               0\n",
            "           Conv2d-74          [-1, 384, 14, 14]         590,208\n",
            "         Identity-75          [-1, 384, 14, 14]               0\n",
            "            Block-76          [-1, 384, 14, 14]               0\n",
            "           Conv2d-77          [-1, 384, 14, 14]          19,200\n",
            "      BatchNorm2d-78          [-1, 384, 14, 14]             768\n",
            "           Conv2d-79         [-1, 1536, 14, 14]         591,360\n",
            "             GELU-80         [-1, 1536, 14, 14]               0\n",
            "           Conv2d-81          [-1, 384, 14, 14]         590,208\n",
            "         Identity-82          [-1, 384, 14, 14]               0\n",
            "            Block-83          [-1, 384, 14, 14]               0\n",
            "           Conv2d-84          [-1, 384, 14, 14]          19,200\n",
            "      BatchNorm2d-85          [-1, 384, 14, 14]             768\n",
            "           Conv2d-86         [-1, 1536, 14, 14]         591,360\n",
            "             GELU-87         [-1, 1536, 14, 14]               0\n",
            "           Conv2d-88          [-1, 384, 14, 14]         590,208\n",
            "         Identity-89          [-1, 384, 14, 14]               0\n",
            "            Block-90          [-1, 384, 14, 14]               0\n",
            "           Conv2d-91          [-1, 384, 14, 14]          19,200\n",
            "      BatchNorm2d-92          [-1, 384, 14, 14]             768\n",
            "           Conv2d-93         [-1, 1536, 14, 14]         591,360\n",
            "             GELU-94         [-1, 1536, 14, 14]               0\n",
            "           Conv2d-95          [-1, 384, 14, 14]         590,208\n",
            "         Identity-96          [-1, 384, 14, 14]               0\n",
            "            Block-97          [-1, 384, 14, 14]               0\n",
            "           Conv2d-98          [-1, 384, 14, 14]          19,200\n",
            "      BatchNorm2d-99          [-1, 384, 14, 14]             768\n",
            "          Conv2d-100         [-1, 1536, 14, 14]         591,360\n",
            "            GELU-101         [-1, 1536, 14, 14]               0\n",
            "          Conv2d-102          [-1, 384, 14, 14]         590,208\n",
            "        Identity-103          [-1, 384, 14, 14]               0\n",
            "           Block-104          [-1, 384, 14, 14]               0\n",
            "          Conv2d-105          [-1, 384, 14, 14]          19,200\n",
            "     BatchNorm2d-106          [-1, 384, 14, 14]             768\n",
            "          Conv2d-107         [-1, 1536, 14, 14]         591,360\n",
            "            GELU-108         [-1, 1536, 14, 14]               0\n",
            "          Conv2d-109          [-1, 384, 14, 14]         590,208\n",
            "        Identity-110          [-1, 384, 14, 14]               0\n",
            "           Block-111          [-1, 384, 14, 14]               0\n",
            "     BatchNorm2d-112          [-1, 384, 14, 14]             768\n",
            "          Conv2d-113            [-1, 758, 7, 7]       1,165,046\n",
            "          Conv2d-114            [-1, 758, 7, 7]          37,900\n",
            "     BatchNorm2d-115            [-1, 758, 7, 7]           1,516\n",
            "          Conv2d-116           [-1, 3032, 7, 7]       2,301,288\n",
            "            GELU-117           [-1, 3032, 7, 7]               0\n",
            "          Conv2d-118            [-1, 758, 7, 7]       2,299,014\n",
            "        Identity-119            [-1, 758, 7, 7]               0\n",
            "           Block-120            [-1, 758, 7, 7]               0\n",
            "          Conv2d-121            [-1, 758, 7, 7]          37,900\n",
            "     BatchNorm2d-122            [-1, 758, 7, 7]           1,516\n",
            "          Conv2d-123           [-1, 3032, 7, 7]       2,301,288\n",
            "            GELU-124           [-1, 3032, 7, 7]               0\n",
            "          Conv2d-125            [-1, 758, 7, 7]       2,299,014\n",
            "        Identity-126            [-1, 758, 7, 7]               0\n",
            "           Block-127            [-1, 758, 7, 7]               0\n",
            "          Conv2d-128            [-1, 758, 7, 7]          37,900\n",
            "     BatchNorm2d-129            [-1, 758, 7, 7]           1,516\n",
            "          Conv2d-130           [-1, 3032, 7, 7]       2,301,288\n",
            "            GELU-131           [-1, 3032, 7, 7]               0\n",
            "          Conv2d-132            [-1, 758, 7, 7]       2,299,014\n",
            "        Identity-133            [-1, 758, 7, 7]               0\n",
            "           Block-134            [-1, 758, 7, 7]               0\n",
            "     BatchNorm2d-135            [-1, 758, 7, 7]           1,516\n",
            "          Linear-136                 [-1, 7000]       5,313,000\n",
            "================================================================\n",
            "Total params: 32,743,164\n",
            "Trainable params: 32,743,164\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 223.56\n",
            "Params size (MB): 124.91\n",
            "Estimated Total Size (MB): 349.04\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = ConvNext(in_channels=3) #initializing an instance of Network class\n",
        "model.cuda() \n",
        "summary(model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf3hr4uOIiXa"
      },
      "outputs": [],
      "source": [
        "class ConvNextBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 stride,\n",
        "                 expand_ratio):\n",
        "        super().__init__() # Just have to do this for all nn.Module classes\n",
        "\n",
        "        # Can only do identity residual connection if input & output are the\n",
        "        # same channel & spatial shape.\n",
        "        if stride == 1 and in_channels == out_channels:\n",
        "            self.do_identity = True\n",
        "        else:\n",
        "            self.do_identity = False\n",
        "        \n",
        "        hidden_dim = in_channels * expand_ratio\n",
        "\n",
        "        self.spatial_mixing = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=7, padding=3,\n",
        "                      stride=stride, groups=in_channels, bias=False),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            # nn.ReLU6(),\n",
        "            \n",
        "        )\n",
        "\n",
        "        self.feature_mixing = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            # nn.BatchNorm2d(hidden_dim),\n",
        "            # nn.ReLU6(),\n",
        "            nn.GELU(),\n",
        "        )\n",
        "\n",
        "        self.bottleneck_channels = nn.Sequential(\n",
        "            nn.Conv2d(hidden_dim, in_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            # nn.BatchNorm2d(hidden_dim),\n",
        "            # nn.ReLU6(),\n",
        "            \n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.spatial_mixing(x) # depthwise convolutions, no of channels remains the same\n",
        "        out = self.feature_mixing(out) # pointwise convolutions, sudden increase in number of channels     \n",
        "        out = self.bottleneck_channels(out)\n",
        "\n",
        "        if self.do_identity:\n",
        "            return x + out # add input to output if no of channels remains the same\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "            \"\"\"\n",
        "        The four numbers in each row (a stage) are shown below.\n",
        "        - Expand ratio: We talked about this in InvertedResidualBlock\n",
        "        - Channels: This specifies the channel size before expansion\n",
        "        - # blocks: Each stage has many blocks, how many?\n",
        "        - Stride of first block: For some stages, we want to downsample. In a\n",
        "          downsampling stage, we set the first block in that stage to have\n",
        "          stride = 2, and the rest just have stride = 1.\n",
        "\n",
        "        Again, note that almost every stage here is downsampling! By the time\n",
        "        we get to the last stage, what is the image resolution? Can it still\n",
        "        be called an image for our dataset? Think about this, and make changes\n",
        "        as you want.\n",
        "        \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NErkTCNAOkZg"
      },
      "source": [
        "ConvNextT class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOD_jWZHOjE_"
      },
      "outputs": [],
      "source": [
        "class ConvNextT(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes= 7000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=4, stride=4, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(96),\n",
        "            # nn.ReLU6(),      \n",
        "        )\n",
        "\n",
        "        self.stage_cfgs = [\n",
        "            # expand_ratio, channels, # blocks, stride of first block\n",
        "            [4,  96, 3, 1],\n",
        "            [4,  192, 3, 1],\n",
        "            [4,  384, 9, 1],\n",
        "            [4,  768, 3, 1],\n",
        "        ]\n",
        "\n",
        "        in_channels = 96\n",
        "\n",
        "        # Let's make the layers\n",
        "        layers = []\n",
        "        for curr_stage in self.stage_cfgs:\n",
        "            expand_ratio, num_channels, num_blocks, stride = curr_stage\n",
        "            \n",
        "            for block_idx in range(num_blocks):\n",
        "                out_channels = num_channels\n",
        "                layers.append(ConvNextBlock(\n",
        "                    in_channels=in_channels,\n",
        "                    out_channels=out_channels,\n",
        "                    # only have non-trivial stride if first block\n",
        "                    stride=stride if block_idx == 0 else 1, \n",
        "                    expand_ratio=expand_ratio\n",
        "                ))\n",
        "                print(\"in: \" + str(in_channels))\n",
        "                print(\"out: \" + str(out_channels))\n",
        "                print(\"\\n\")\n",
        "                # In channels of the next block is the out_channels of the current one\n",
        "                in_channels = out_channels \n",
        "            \n",
        "        self.layers = nn.Sequential(*layers) # Done, save them to the class\n",
        "\n",
        "        # Now, we need to build the final classification layer.\n",
        "        self.cls_layer = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        # Separating linear layer so features can be extracted for verification\n",
        "        # self.lin = nn.Linear(1280, num_classes)\n",
        "        self.lin = nn.Linear(in_channels, num_classes)\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"\n",
        "        Usually, I like to use default pytorch initialization for stuff, but\n",
        "        MobileNetV2 made a point of putting in some custom ones, so let's just\n",
        "        use them.\n",
        "        \"\"\"\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, return_feats=False):\n",
        "        out = self.stem(x)\n",
        "        out = self.layers(out)\n",
        "        # out = self.final_block(out)\n",
        "        feats = self.cls_layer(out)\n",
        "        out = self.lin(feats)\n",
        "\n",
        "        if return_feats:\n",
        "            return feats\n",
        "        else:\n",
        "            return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSBjk0huxV-W"
      },
      "source": [
        "## Loading data and data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hECSdRapyimp",
        "outputId": "33600e64-3d68-448c-b78b-e50ff159806a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in: 96\n",
            "out: 96\n",
            "\n",
            "\n",
            "in: 96\n",
            "out: 96\n",
            "\n",
            "\n",
            "in: 96\n",
            "out: 96\n",
            "\n",
            "\n",
            "in: 96\n",
            "out: 192\n",
            "\n",
            "\n",
            "in: 192\n",
            "out: 192\n",
            "\n",
            "\n",
            "in: 192\n",
            "out: 192\n",
            "\n",
            "\n",
            "in: 192\n",
            "out: 384\n",
            "\n",
            "\n",
            "in: 384\n",
            "out: 384\n",
            "\n",
            "\n",
            "in: 384\n",
            "out: 384\n",
            "\n",
            "\n",
            "in: 384\n",
            "out: 384\n",
            "\n",
            "\n",
            "in: 384\n",
            "out: 384\n",
            "\n",
            "\n",
            "in: 384\n",
            "out: 384\n",
            "\n",
            "\n",
            "in: 384\n",
            "out: 384\n",
            "\n",
            "\n",
            "in: 384\n",
            "out: 384\n",
            "\n",
            "\n",
            "in: 384\n",
            "out: 384\n",
            "\n",
            "\n",
            "in: 384\n",
            "out: 768\n",
            "\n",
            "\n",
            "in: 768\n",
            "out: 768\n",
            "\n",
            "\n",
            "in: 768\n",
            "out: 768\n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-219977833fde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNextT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#initializing an instance of Network class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-b1c33c5fe1f9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, return_feats)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_feats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;31m# out = self.final_block(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-97474ad5ecc5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial_mixing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# depthwise convolutions, no of channels remains the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_mixing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# pointwise convolutions, sudden increase in number of channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottleneck_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=192, weight of size [192, 1, 7, 7], expected input[2, 96, 56, 56] to have 192 channels, but got 96 channels instead"
          ]
        }
      ],
      "source": [
        "model = ConvNextT() #initializing an instance of Network class\n",
        "model.cuda() \n",
        "summary(model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKvKA7eUxY-y",
        "outputId": "11829a51-def0-4dd1-b55b-1c2a99d66db1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "Transforms (data augmentation) is quite important for this task.\n",
        "Go explore https://pytorch.org/vision/stable/transforms.html for more details\n",
        "\"\"\"\n",
        "DATA_DIR = \"/content\"\n",
        "# TRAIN_DIR = osp.join(DATA_DIR, \"train_subset/train_subset\") # This is a smaller subset of the data. Should change this to classification/classification/train\n",
        "TRAIN_DIR = osp.join(DATA_DIR, \"classification/classification/train\")\n",
        "VAL_DIR = osp.join(DATA_DIR, \"classification/classification/dev\")\n",
        "TEST_DIR = osp.join(DATA_DIR, \"classification/classification/test\")\n",
        "\n",
        "train_transforms = [ttf.ToTensor(), ttf.ColorJitter(brightness=(0.8,1.2), contrast=(0.8,1.2), saturation=(0.8,1.2)),\n",
        "                     ttf.RandomHorizontalFlip(p=0.5)]\n",
        "val_transforms = [ttf.ToTensor()]\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(TRAIN_DIR,\n",
        "                                                 transform=ttf.Compose(train_transforms))\n",
        "val_dataset = torchvision.datasets.ImageFolder(VAL_DIR,\n",
        "                                               transform=ttf.Compose(val_transforms))\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                          shuffle=True, drop_last=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                        drop_last=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(train_dataset[0][0].size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLQOcvc6yD_7"
      },
      "source": [
        "# Setup everything for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlB2Y-ezW8ju",
        "outputId": "f6fc2243-5395-4818-9e57-e242b98852e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "200\n"
          ]
        }
      ],
      "source": [
        "for i, (x, y) in enumerate(train_loader):\n",
        "  print(len(y))\n",
        "  if i>0:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vajIstsqyGN0",
        "outputId": "f6e56d55-15f5-4e16-f649-74cf27e3ad1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Params: 32743164\n"
          ]
        }
      ],
      "source": [
        "model = ConvNext(in_channels=3) #initializing an instance of Network class\n",
        "model.cuda() #to move parameters to GPU\n",
        "\n",
        "num_trainable_parameters = 0\n",
        "for p in model.parameters():\n",
        "    num_trainable_parameters += p.numel()\n",
        "print(\"Number of Params: {}\".format(num_trainable_parameters))\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.3)\n",
        "\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * n_epochs))\n",
        "# T_max is \"how many times will i call scheduler.step() until it reaches 0 lr?\"\n",
        "\n",
        "# For this homework, we strongly strongly recommend using FP16 to speed up training.\n",
        "# It helps more for larger models.\n",
        "# Go to https://effectivemachinelearning.com/PyTorch/8._Faster_training_with_mixed_precision\n",
        "# and compare \"Single precision training\" section with \"Mixed precision training\" section\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYNmXeRcMl5p"
      },
      "source": [
        "\n",
        "Model checkpoint saving function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTmYGByiMkhy"
      },
      "outputs": [],
      "source": [
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "    \"\"\"\n",
        "    state: checkpoint we want to save\n",
        "    is_best: is this the best checkpoint; min validation loss\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    best_model_path: path to save best model\n",
        "    \"\"\"\n",
        "    f_path = checkpoint_path\n",
        "    # save checkpoint data to the path given, checkpoint_path\n",
        "    torch.save(state, f_path)\n",
        "    # if it is a best model, min validation loss\n",
        "    if is_best:\n",
        "        best_fpath = best_model_path\n",
        "        # copy that checkpoint file to best path given, best_model_path\n",
        "        shutil.copyfile(f_path, best_fpath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZs-09nRNSNz"
      },
      "source": [
        "Checkpoint loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQwOoxl7NRza"
      },
      "outputs": [],
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer, scheduler):\n",
        "    \"\"\"\n",
        "    checkpoint_path: path to save checkpoint\n",
        "    model: model that we want to load checkpoint parameters into       \n",
        "    optimizer: optimizer we defined in previous training\n",
        "    \"\"\"\n",
        "    # load check point\n",
        "    checkpoint = torch.load(checkpoint_fpath)\n",
        "    # initialize state_dict from checkpoint to model\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    # initialize optimizer from checkpoint to optimizer\n",
        "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "    valid_acc_max = checkpoint['valid_acc_max']\n",
        "    # return model, optimizer, epoch value, min validation loss \n",
        "    return model, optimizer, checkpoint['epoch'], scheduler, valid_acc_max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDXuAxu1k-AZ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RH_UeDobOa7f"
      },
      "outputs": [],
      "source": [
        "def train(start_epochs, n_epochs, valid_acc_max_input, train_loader, val_loader,val_dataset, model, optimizer, criterion, checkpoint_path, best_model_path):\n",
        "\n",
        "  # initialize tracker for minimum validation loss\n",
        "  valid_acc_max = valid_acc_max_input \n",
        "\n",
        "  for epoch in range(start_epochs, n_epochs+1):\n",
        "  # Quality of life tip: leave=False and position=0 are needed to make tqdm usable in jupyter\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "\n",
        "    num_correct = 0\n",
        "    total_loss = 0\n",
        "    total_loss_val = 0\n",
        "\n",
        "    # training\n",
        "    model.train()\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      x = x.cuda() # moving data to GPU\n",
        "      y = y.cuda()\n",
        "\n",
        "      # Don't be surprised - we just wrap these two lines to make it work for FP16\n",
        "      with torch.cuda.amp.autocast():     \n",
        "          outputs = model(x)\n",
        "          loss = criterion(outputs, y)\n",
        "\n",
        "      # Update # correct & loss as we go\n",
        "      num_correct += int((torch.argmax(outputs, axis=1) == y).sum())\n",
        "      total_loss += float(loss)\n",
        "\n",
        "      # tqdm lets you add some details so you can monitor training as you train.\n",
        "      batch_bar.set_postfix(\n",
        "          acc=\"{:.04f}%\".format(100 * num_correct / ((i + 1) * batch_size)),\n",
        "          loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "          num_correct=num_correct,\n",
        "          lr=\"{:.04f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "      \n",
        "      # Another couple things you need for FP16. \n",
        "      scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "      scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "      scaler.update() # This is something added just for FP16\n",
        "\n",
        "      scheduler.step() # We told scheduler T_max that we'd call step() (len(train_loader) * epochs) many times.\n",
        "\n",
        "      batch_bar.update() # Update tqdm bar\n",
        "\n",
        "      # to avoid cuda out of memory error\n",
        "      del x\n",
        "      del y\n",
        "      del loss\n",
        "\n",
        "    batch_bar.close()\n",
        "\n",
        "    # Validation \n",
        "    model.eval()\n",
        "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "    num_correct_val = 0\n",
        "    for i, (x, y) in enumerate(val_loader):\n",
        "      x = x.cuda()\n",
        "      y = y.cuda()\n",
        "\n",
        "      with torch.no_grad():\n",
        "          outputs = model(x)\n",
        "          loss = criterion(outputs, y)\n",
        "\n",
        "      num_correct_val += int((torch.argmax(outputs, axis=1) == y).sum())\n",
        "      total_loss_val += float(loss)\n",
        "      batch_bar.set_postfix(acc=\"{:.04f}%\".format(100 * num_correct_val/ ((i + 1) * batch_size)))\n",
        "\n",
        "      batch_bar.update()\n",
        "\n",
        "      # to avoid cuda out of memory error\n",
        "      del x\n",
        "      del y\n",
        "      del loss\n",
        "    batch_bar.close()\n",
        "    \n",
        "    val_acc = 100 * num_correct_val / len(val_dataset)\n",
        "\n",
        "    print(\"Val acc: {:.04f}%\".format(val_acc))\n",
        "\n",
        "    print(\"Epoch {}/{}: Train Acc {:.04f}%, Val acc: {:.04f}%, Train Loss {:.04f}, Learning Rate {:.04f}\".format(\n",
        "        epoch,\n",
        "        n_epochs,\n",
        "        100 * num_correct / (len(train_loader) * batch_size),\n",
        "        val_acc,\n",
        "        float(total_loss / len(train_loader)),\n",
        "        float(optimizer.param_groups[0]['lr'])))\n",
        "\n",
        "    \n",
        "\n",
        "    # create checkpoint variable and add important data\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'valid_acc_max': val_acc,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'scheduler': scheduler.state_dict()\n",
        "    }\n",
        "\n",
        "    # save checkpoint\n",
        "    save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
        "        \n",
        "    ## save the model if validation acc has increased\n",
        "    if val_acc >= valid_acc_max:\n",
        "        print('Validation acc increased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_acc_max,val_acc))\n",
        "        # save checkpoint as best model\n",
        "        save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "        valid_acc_max = val_acc\n",
        "    \n",
        "  return model\n",
        "\n",
        "\n",
        "# torch.save(model.state_dict(), \"/content/drive/MyDrive/MobileNetV2.pth\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwbrgM3KkM6C",
        "outputId": "3cbba07f-8668-4a33-ea4d-ff7c9bcdc4e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 0.5714%\n",
            "Epoch 1/70: Train Acc 0.1429%, Val acc: 0.5714%, Train Loss 8.6469, Learning Rate 0.0999\n",
            "Validation acc increased (-inf --> 0.571429).  Saving model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 4.0000%\n",
            "Epoch 2/70: Train Acc 1.8614%, Val acc: 4.0000%, Train Loss 8.0181, Learning Rate 0.0998\n",
            "Validation acc increased (0.571429 --> 4.000000).  Saving model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 15.2400%\n",
            "Epoch 3/70: Train Acc 9.5671%, Val acc: 15.2400%, Train Loss 7.3111, Learning Rate 0.0995\n",
            "Validation acc increased (4.000000 --> 15.240000).  Saving model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 29.2514%\n",
            "Epoch 4/70: Train Acc 26.1886%, Val acc: 29.2514%, Train Loss 6.5815, Learning Rate 0.0992\n",
            "Validation acc increased (15.240000 --> 29.251429).  Saving model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 46.1914%\n",
            "Epoch 5/70: Train Acc 46.3079%, Val acc: 46.1914%, Train Loss 5.9040, Learning Rate 0.0987\n",
            "Validation acc increased (29.251429 --> 46.191429).  Saving model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 56.9143%\n",
            "Epoch 6/70: Train Acc 61.9636%, Val acc: 56.9143%, Train Loss 5.3617, Learning Rate 0.0982\n",
            "Validation acc increased (46.191429 --> 56.914286).  Saving model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 62.8743%\n",
            "Epoch 7/70: Train Acc 72.8536%, Val acc: 62.8743%, Train Loss 4.9593, Learning Rate 0.0976\n",
            "Validation acc increased (56.914286 --> 62.874286).  Saving model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 68.9800%\n",
            "Epoch 8/70: Train Acc 80.0829%, Val acc: 68.9800%, Train Loss 4.6655, Learning Rate 0.0968\n",
            "Validation acc increased (62.874286 --> 68.980000).  Saving model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 69.9086%\n",
            "Epoch 9/70: Train Acc 85.1057%, Val acc: 69.9086%, Train Loss 4.4441, Learning Rate 0.0960\n",
            "Validation acc increased (68.980000 --> 69.908571).  Saving model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 71.5057%\n",
            "Epoch 10/70: Train Acc 88.5857%, Val acc: 71.5057%, Train Loss 4.2740, Learning Rate 0.0950\n",
            "Validation acc increased (69.908571 --> 71.505714).  Saving model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 73.4229%\n",
            "Epoch 11/70: Train Acc 91.3943%, Val acc: 73.4229%, Train Loss 4.1339, Learning Rate 0.0940\n",
            "Validation acc increased (71.505714 --> 73.422857).  Saving model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 73.9143%\n",
            "Epoch 12/70: Train Acc 93.6543%, Val acc: 73.9143%, Train Loss 4.0192, Learning Rate 0.0929\n",
            "Validation acc increased (73.422857 --> 73.914286).  Saving model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 70.2200%\n",
            "Epoch 13/70: Train Acc 95.6586%, Val acc: 70.2200%, Train Loss 3.9206, Learning Rate 0.0917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 73.8629%\n",
            "Epoch 14/70: Train Acc 97.3543%, Val acc: 73.8629%, Train Loss 3.8387, Learning Rate 0.0905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 74.8371%\n",
            "Epoch 15/70: Train Acc 98.4893%, Val acc: 74.8371%, Train Loss 3.7732, Learning Rate 0.0891\n",
            "Validation acc increased (73.914286 --> 74.837143).  Saving model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 72.0229%\n",
            "Epoch 16/70: Train Acc 99.0686%, Val acc: 72.0229%, Train Loss 3.7293, Learning Rate 0.0877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 75.4914%\n",
            "Epoch 17/70: Train Acc 99.3707%, Val acc: 75.4914%, Train Loss 3.6961, Learning Rate 0.0861\n",
            "Validation acc increased (74.837143 --> 75.491429).  Saving model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 70.2314%\n",
            "Epoch 18/70: Train Acc 99.5300%, Val acc: 70.2314%, Train Loss 3.6699, Learning Rate 0.0846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 74.2171%\n",
            "Epoch 19/70: Train Acc 99.6193%, Val acc: 74.2171%, Train Loss 3.6535, Learning Rate 0.0829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 75.8400%\n",
            "Epoch 20/70: Train Acc 99.6936%, Val acc: 75.8400%, Train Loss 3.6366, Learning Rate 0.0812\n",
            "Validation acc increased (75.491429 --> 75.840000).  Saving model ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 73.1657%\n",
            "Epoch 21/70: Train Acc 99.7621%, Val acc: 73.1657%, Train Loss 3.6231, Learning Rate 0.0794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 72.6514%\n",
            "Epoch 22/70: Train Acc 99.7993%, Val acc: 72.6514%, Train Loss 3.6105, Learning Rate 0.0775\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 58.5686%\n",
            "Epoch 23/70: Train Acc 99.8179%, Val acc: 58.5686%, Train Loss 3.6006, Learning Rate 0.0756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  13%|█▎        | 89/700 [02:39<17:57,  1.76s/it, acc=99.8000%, loss=3.5952, lr=0.0754, num_correct=17964]"
          ]
        }
      ],
      "source": [
        "# to avoid cuda out of memory error\n",
        "torch.cuda.empty_cache( )\n",
        "gc.collect( )\n",
        "\n",
        "# NINF is negative infinity\n",
        "trained_model = train(1, n_epochs, np.NINF, train_loader, val_loader, val_dataset, model, optimizer, criterion, \"/content/drive/MyDrive/hw2p2_saved_models/current_checkpoint.pt\", \"/content/drive/MyDrive/hw2p2_saved_models/best_model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1A8rPnyq48x"
      },
      "outputs": [],
      "source": [
        "# define optimzer\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(len(train_loader) * n_epochs))\n",
        "# define checkpoint saved path\n",
        "ckp_path = \"/content/drive/MyDrive/hw2p2_saved_models/best_model.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSd0Av96sTyv"
      },
      "outputs": [],
      "source": [
        "# load the saved checkpoint\n",
        "model, optimizer, epoch, scheduler, valid_acc_max = load_ckp(ckp_path, model, optimizer, scheduler)\n",
        "start_epoch = epoch+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uIGGSucrSYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed3c8ca2-304c-44fa-e004-77768ad65d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model =  ConvNext(\n",
            "  (down_sample_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (1): Conv2d(384, 758, kernel_size=(2, 2), stride=(2, 2))\n",
            "    )\n",
            "  )\n",
            "  (block_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
            "        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
            "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (3): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (4): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (5): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (6): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (7): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (8): Block(\n",
            "        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
            "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Block(\n",
            "        (dwconv): Conv2d(758, 758, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=758)\n",
            "        (bn): BatchNorm2d(758, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(758, 3032, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(3032, 758, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (1): Block(\n",
            "        (dwconv): Conv2d(758, 758, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=758)\n",
            "        (bn): BatchNorm2d(758, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(758, 3032, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(3032, 758, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "      (2): Block(\n",
            "        (dwconv): Conv2d(758, 758, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=758)\n",
            "        (bn): BatchNorm2d(758, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (pwconv1): Conv2d(758, 3032, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (act): GELU()\n",
            "        (pwconv2): Conv2d(3032, 758, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (drop_path): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): BatchNorm2d(758, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (classifier): Linear(in_features=758, out_features=7000, bias=True)\n",
            ")\n",
            "optimizer =  SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    initial_lr: 0.1\n",
            "    lr: 5.0346672934271046e-05\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0001\n",
            ")\n",
            "scheduler=  <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f13df90a9d0>\n",
            "start_epoch =  70\n",
            "valid_acc_max = 87.47428571428571%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"model = \", model)\n",
        "print(\"optimizer = \", optimizer)\n",
        "print(\"scheduler= \", scheduler)\n",
        "print(\"start_epoch = \", start_epoch)\n",
        "# print(\"valid_acc_min = {}\".format(valid_acc_max)\n",
        "print(\"valid_acc_max = {}%\".format(valid_acc_max))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "qRg4wTZMtHwp",
        "outputId": "a76145a9-3fca-4ce8-cfdc-335e9c31c7b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 59.4800%\n",
            "Epoch 21/50: Train Acc 96.6825%, Val acc: 59.4800%, Train Loss 0.3169, Learning Rate 0.0006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 59.4400%\n",
            "Epoch 22/50: Train Acc 96.5874%, Val acc: 59.4400%, Train Loss 0.3217, Learning Rate 0.0024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 59.0943%\n",
            "Epoch 23/50: Train Acc 96.4965%, Val acc: 59.0943%, Train Loss 0.3292, Learning Rate 0.0054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 58.5914%\n",
            "Epoch 24/50: Train Acc 96.3928%, Val acc: 58.5914%, Train Loss 0.3379, Learning Rate 0.0095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 57.8200%\n",
            "Epoch 25/50: Train Acc 96.1088%, Val acc: 57.8200%, Train Loss 0.3499, Learning Rate 0.0146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val acc: 54.4286%\n",
            "Epoch 26/50: Train Acc 95.4449%, Val acc: 54.4286%, Train Loss 0.3765, Learning Rate 0.0206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  59%|█████▉    | 323/546 [03:07<02:09,  1.72it/s, acc=95.0171%, loss=0.3826, lr=0.0245, num_correct=78811]"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-99b1b3c2c6ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/hw2p2_saved_models/current_checkpoint.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/hw2p2_saved_models/best_model.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-6acb6ed35c11>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(start_epochs, n_epochs, valid_acc_max_input, train_loader, val_loader, val_dataset, model, optimizer, criterion, checkpoint_path, best_model_path)\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0;31m# Another couple things you need for FP16.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is a replacement for loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is a replacement for optimizer.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m       \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is something added just for FP16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trained_model = train(start_epoch, 50, valid_acc_max, train_loader, val_loader, val_dataset, model, optimizer, criterion, \"/content/drive/MyDrive/hw2p2_saved_models/current_checkpoint.pt\", \"/content/drive/MyDrive/hw2p2_saved_models/best_model.pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwb5nqxKn3xV"
      },
      "source": [
        "## Testing classification and generating submission file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHb-lMvsnY29"
      },
      "outputs": [],
      "source": [
        "class ClassificationTestSet(Dataset):\n",
        "    # It's possible to load test set data using ImageFolder without making a custom class.\n",
        "    # See if you can think it through!\n",
        "\n",
        "    def __init__(self, data_dir, transforms):\n",
        "        self.data_dir = data_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "        # This one-liner basically generates a sorted list of full paths to each image in data_dir\n",
        "        self.img_paths = list(map(lambda fname: osp.join(self.data_dir, fname), sorted(os.listdir(self.data_dir))))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.transforms(Image.open(self.img_paths[idx]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mj0U99vVncKu"
      },
      "outputs": [],
      "source": [
        "test_dataset = ClassificationTestSet(TEST_DIR, ttf.Compose(val_transforms))\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
        "                         drop_last=False, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "I9ZhyuUMngfI",
        "outputId": "cf7c6753-a186-4669-d453-93815560755a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Test:  34%|███▎      | 46/137 [00:27<00:52,  1.73it/s]"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-45b09b395245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# TODO: Finish predicting on the test set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "batch_bar = tqdm(total=len(test_loader), dynamic_ncols=True, position=0, leave=False, desc='Test')\n",
        "\n",
        "res = []\n",
        "for i, (x) in enumerate(test_loader):\n",
        "\n",
        "    # TODO: Finish predicting on the test set.\n",
        "    x = x.cuda()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(x)\n",
        "        \n",
        "    pred_y = torch.argmax(outputs, axis=1)\n",
        "    res.extend(pred_y.tolist())\n",
        "\n",
        "    batch_bar.update()\n",
        "    \n",
        "batch_bar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDK6UfPbninc"
      },
      "outputs": [],
      "source": [
        "with open(\"classification_early_submission.csv\", \"w+\") as f:\n",
        "    f.write(\"id,label\\n\")\n",
        "    for i in range(len(test_dataset)):\n",
        "        f.write(\"{},{}\\n\".format(str(i).zfill(6) + \".jpg\", res[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2XRpeY9T0bET"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNCo_PC9njaQ"
      },
      "source": [
        "##Submission to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVeEleW7nmJP",
        "outputId": "98ef795d-c240-466e-99af-73e81d821f8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.8)\n",
            "100% 541k/541k [00:00<00:00, 2.57MB/s]\n",
            "Successfully submitted to Face Recognition"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c 11-785-s22-hw2p2-classification -f classification_early_submission.csv -m \"MobileNetV2_fulldata\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8kAG_-qahTd"
      },
      "source": [
        "## Verification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDcmUsNZaudH"
      },
      "source": [
        "Downloading verif data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LhJ5YT3Zbsj",
        "outputId": "d6f25eea-ab79-4ce2-95b0-3b375fc1fd8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6000\n",
            "166801\n"
          ]
        }
      ],
      "source": [
        "!ls verification/verification/dev | wc -l\n",
        "!cat verification/verification/verification_dev.csv | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sch_3HJcatFt"
      },
      "outputs": [],
      "source": [
        "class VerificationDataset(Dataset):\n",
        "    def __init__(self, data_dir, transforms):\n",
        "        self.data_dir = data_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "        # This one-liner basically generates a sorted list of full paths to each image in data_dir\n",
        "        self.img_paths = list(map(lambda fname: osp.join(self.data_dir, fname), sorted(os.listdir(self.data_dir))))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # We return the image, as well as the path to that image (relative path)\n",
        "        return self.transforms(Image.open(self.img_paths[idx])), osp.relpath(self.img_paths[idx], self.data_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4h5ByqrQMnik"
      },
      "source": [
        "Verification: Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-H30Xj7wMUMe"
      },
      "outputs": [],
      "source": [
        "val_veri_dataset = VerificationDataset(osp.join(DATA_DIR, \"verification/verification/dev\"),\n",
        "                                       ttf.Compose(val_transforms))\n",
        "val_ver_loader = torch.utils.data.DataLoader(val_veri_dataset, batch_size=batch_size, \n",
        "                                             shuffle=False, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWLXHXT_MWmt",
        "outputId": "ac5f8fb7-89c6-4661-cb10-a2b6af6075e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "feats_dict = dict()\n",
        "for batch_idx, (imgs, path_names) in tqdm(enumerate(val_ver_loader), total=len(val_ver_loader), position=0, leave=False):\n",
        "    imgs = imgs.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Note that we return the feats here, not the final outputs\n",
        "        # Feel free to try the final outputs too!\n",
        "        feats = model(imgs, return_features=True) \n",
        "    \n",
        "    # TODO: Now we have features and the image path names. What to do with them?\n",
        "    # Hint: use the feats_dict somehow.\n",
        "    # feats_dict[path_names] = feats\n",
        "    for index, value in enumerate(path_names):\n",
        "      feats_dict[value] = feats[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0FSlrzPMaag",
        "outputId": "3943dbc1-6971-45c7-8c55-7736e40c31f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.9666614044995622\n"
          ]
        }
      ],
      "source": [
        "# We use cosine similarity between feature embeddings.\n",
        "# TODO: Find the relevant function in pytorch and read its documentation.\n",
        "similarity_metric = torch.nn.CosineSimilarity(dim=0, eps=1e-6) \n",
        "\n",
        "val_veri_csv = osp.join(DATA_DIR, \"verification/verification/verification_dev.csv\")\n",
        "\n",
        "\n",
        "# Now, loop through the csv and compare each pair, getting the similarity between them\n",
        "pred_similarities = []\n",
        "gt_similarities = []\n",
        "for line in tqdm(open(val_veri_csv).read().splitlines()[1:], position=0, leave=False): # skip header\n",
        "    img_path1, img_path2, gt = line.split(\",\")\n",
        "\n",
        "    # TODO: Use the similarity metric\n",
        "    # How to use these img_paths? What to do with the features?\n",
        "    img_path1 = img_path1.split(\"/\")[1]\n",
        "    img_path2 = img_path2.split(\"/\")[1]\n",
        "    similarity = float(similarity_metric( feats_dict[img_path1], feats_dict[img_path2] ))\n",
        "\n",
        "    gt_similarities.append(int(gt))\n",
        "    pred_similarities.append(similarity)\n",
        "\n",
        "\n",
        "pred_similarities = np.array(pred_similarities)\n",
        "gt_similarities = np.array(gt_similarities)\n",
        "\n",
        "print(\"AUC:\", roc_auc_score(gt_similarities, pred_similarities))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeNgCtLUMg9l"
      },
      "source": [
        "Verification: Testing and submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORDgtJTnbf2v"
      },
      "outputs": [],
      "source": [
        "test_veri_dataset = VerificationDataset(osp.join(DATA_DIR, \"verification/verification/test\"),\n",
        "                                        ttf.Compose(val_transforms))\n",
        "test_ver_loader = torch.utils.data.DataLoader(test_veri_dataset, batch_size=batch_size, \n",
        "                                              shuffle=False, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfwDdE2PbiTM",
        "outputId": "28d99973-0869-434d-cc6b-dbea3c8f1baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "feats_dict = dict()\n",
        "for batch_idx, (imgs, path_names) in tqdm(enumerate(test_ver_loader), total=len(test_ver_loader), position=0, leave=False):\n",
        "    imgs = imgs.cuda()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Note that we return the feats here, not the final outputs\n",
        "        # Feel free to try to final outputs too!\n",
        "        feats = model(imgs, return_features=True) \n",
        "    \n",
        "    # TODO: Now we have features and the image path names. What to do with them?\n",
        "    # Hint: use the feats_dict somehow.\n",
        "    for index, value in enumerate(path_names):\n",
        "      feats_dict[value] = feats[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIKd5nc2bj0E",
        "outputId": "351c0afb-3a0c-4b36-ef7d-1aff0c638f04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        }
      ],
      "source": [
        "# We use cosine similarity between feature embeddings.\n",
        "# TODO: Find the relevant function in pytorch and read its documentation.\n",
        "similarity_metric = torch.nn.CosineSimilarity(dim=0, eps=1e-6) \n",
        "val_veri_csv = osp.join(DATA_DIR, \"verification/verification/verification_test.csv\")\n",
        "\n",
        "\n",
        "# Now, loop through the csv and compare each pair, getting the similarity between them\n",
        "pred_similarities = []\n",
        "for line in tqdm(open(val_veri_csv).read().splitlines()[1:], position=0, leave=False): # skip header\n",
        "    img_path1, img_path2 = line.split(\",\")\n",
        "\n",
        "    # TODO: Finish up verification testing.\n",
        "    # How to use these img_paths? What to do with the features?\n",
        "    img_path1 = img_path1.split(\"/\")[1]\n",
        "    img_path2 = img_path2.split(\"/\")[1]\n",
        "    similarity = float(similarity_metric( feats_dict[img_path1], feats_dict[img_path2] ))\n",
        "\n",
        "    # gt_similarities.append(int(gt))\n",
        "    pred_similarities.append(similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5qHYyLabl_n"
      },
      "outputs": [],
      "source": [
        "with open(\"verification_early_submission.csv\", \"w+\") as f:\n",
        "    f.write(\"id,match\\n\")\n",
        "    for i in range(len(pred_similarities)):\n",
        "        f.write(\"{},{}\\n\".format(i, pred_similarities[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfku9tPObpkQ",
        "outputId": "5ea2e198-79a8-4497-8be1-f88c03588573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.8)\n",
            "100% 16.9M/16.9M [00:05<00:00, 2.95MB/s]\n",
            "Successfully submitted to Face Verification"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c 11-785-s22-hw2p2-verification -f verification_early_submission.csv -m \"Convnext 70 epochs return final layer cat with out through many gelus\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjwAZfT39uMK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}